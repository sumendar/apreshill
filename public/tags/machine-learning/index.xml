<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Shirin&#39;s playgRound</title>
    <link>/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Shirin&#39;s playgRound</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Code for Workshop: Introduction to Machine Learning with R</title>
      <link>/2018/06/intro_to_ml_workshop_heidelberg/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/06/intro_to_ml_workshop_heidelberg/</guid>
      <description>These are the slides from my workshop: Introduction to Machine Learning with R which I gave at the University of Heidelberg, Germany on June 28th 2018. The entire code accompanying the workshop can be found below the video.
The workshop covered the basics of machine learning. With an example dataset I went through a standard machine learning workflow in R with the packages caret and h2o:
 reading in data exploratory data analysis missingness feature engineering training and test split model training with Random Forests, Gradient Boosting, Neural Nets, etc.</description>
    </item>
    
    <item>
      <title>Sketchnotes from TWiML&amp;AI: Practical Deep Learning with Rachel Thomas</title>
      <link>/2018/06/twimlai138/</link>
      <pubDate>Mon, 18 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/06/twimlai138/</guid>
      <description>These are my sketchnotes for Sam Charrington’s podcast This Week in Machine Learning and AI about Practical Deep Learning with Rachel Thomas:
Sketchnotes from TWiMLAI talk: Practical Deep Learning with Rachel Thomas
 You can listen to the podcast here.
 In this episode, i’m joined by Rachel Thomas, founder and researcher at Fast AI. If you’re not familiar with Fast AI, the company offers a series of courses including Practical Deep Learning for Coders, Cutting Edge Deep Learning for Coders and Rachel’s Computational Linear Algebra course.</description>
    </item>
    
    <item>
      <title>Sketchnotes from TWiML&amp;AI: Adversarial Attacks Against Reinforcement Learning Agents with Ian Goodfellow &amp; Sandy Huang</title>
      <link>/2018/05/twimlai_adversarial_attacks/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/twimlai_adversarial_attacks/</guid>
      <description>These are my sketchnotes for Sam Charrington’s podcast This Week in Machine Learning and AI about Adversarial Attacks Against Reinforcement Learning Agents with Ian Goodfellow &amp;amp; Sandy Huang:
Sketchnotes from TWiMLAI talk: Adversarial Attacks Against Reinforcement Learning Agents with Ian Goodfellow &amp;amp; Sandy Huang
 You can listen to the podcast here.
 In this episode, I’m joined by Ian Goodfellow, Staff Research Scientist at Google Brain and Sandy Huang, Phd Student in the EECS department at UC Berkeley, to discuss their work on the paper Adversarial Attacks on Neural Network Policies.</description>
    </item>
    
    <item>
      <title>Comparing dependencies of popular machine learning packages with `pkgnet`</title>
      <link>/2018/04/pkgnet/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/pkgnet/</guid>
      <description>When looking through the CRAN list of packages, I stumbled upon this little gem:
 pkgnet is an R library designed for the analysis of R libraries! The goal of the package is to build a graph representation of a package and its dependencies.
 And I thought it would be fun to play around with it. The little analysis I ended up doing was to compare dependencies of popular machine learning packages.</description>
    </item>
    
    <item>
      <title>Slides from my JAX 2018 talk: Deep Learning - a Primer</title>
      <link>/2018/04/jax2018_slides/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/jax2018_slides/</guid>
      <description>Here I am sharing the slides for a talk that my colleague Uwe Friedrichsen and I gave about Deep Learning - a Primer at the JAX conference on Tuesday, April 24th 2018 in Mainz, Germany.
Slides can be found here: https://www.slideshare.net/ShirinGlander/deep-learning-a-primer-95197733
 Deep Learning is one of the “hot” topics in the AI area – a lot of hype, a lot of inflated expectation, but also quite some impressive success stories.</description>
    </item>
    
    <item>
      <title>Sketchnotes from TWiML&amp;AI #121: Reproducibility and the Philosophy of Data with Clare Gollnick</title>
      <link>/2018/04/twimlai121/</link>
      <pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/twimlai121/</guid>
      <description>These are my sketchnotes for Sam Charrington’s podcast This Week in Machine Learning and AI about Reproducibility and the Philosophy of Data with Clare Gollnick:
Sketchnotes from TWiMLAI talk #121: Reproducibility and the Philosophy of Data with Clare Gollnick
 You can listen to the podcast here.
 In this episode, i’m joined by Clare Gollnick, CTO of Terbium Labs, to discuss her thoughts on the “reproducibility crisis” currently haunting the scientific landscape.</description>
    </item>
    
    <item>
      <title>Update: Can we predict flu outcome with Machine Learning in R?</title>
      <link>/2018/04/flu_prediction/</link>
      <pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/flu_prediction/</guid>
      <description>Since I migrated my blog from Github Pages to blogdown and Netlify, I wanted to start migrating (most of) my old posts too - and use that opportunity to update them and make sure the code still works.
Here I am updating my very first machine learning post from 27 Nov 2016: Can we predict flu deaths with Machine Learning and R?. Changes are marked as bold comments.
The main changes I made are:</description>
    </item>
    
    <item>
      <title>HH Data Science Meetup slides: Explaining complex machine learning models with LIME</title>
      <link>/2018/04/hh_datascience_meetup_2018_slides/</link>
      <pubDate>Wed, 18 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/hh_datascience_meetup_2018_slides/</guid>
      <description>On April 12th, 2018 I gave a talk about Explaining complex machine learning models with LIME at the Hamburg Data Science Meetup - so if you’re intersted: the slides can be found here: https://www.slideshare.net/ShirinGlander/hh-data-science-meetup-explaining-complex-machine-learning-models-with-lime-94218890
 Traditional machine learning workflows focus heavily on model training and optimization; the best model is usually chosen via performance measures like accuracy or error and we tend to assume that a model is good enough for deployment if it passes certain thresholds of these performance criteria.</description>
    </item>
    
    <item>
      <title>Sketchnotes from TWiML&amp;AI #124: Systems and Software for Machine Learning at Scale with Jeff Dean</title>
      <link>/2018/04/twimlai124/</link>
      <pubDate>Wed, 18 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/twimlai124/</guid>
      <description>These are my sketchnotes for Sam Charrington’s podcast This Week in Machine Learning and AI about Systems and Software for Machine Learning at Scale with Jeff Dean:
Sketchnotes from TWiMLAI talk #124: Systems and Software for Machine Learning at Scale with Jeff Dean
 You can listen to the podcast here.
 In this episode I’m joined by Jeff Dean, Google Senior Fellow and head of the company’s deep learning research team Google Brain, who I had a chance to sit down with last week at the Googleplex in Mountain View.</description>
    </item>
    
    <item>
      <title>Meetup slides: Introducing Deep Learning with Keras</title>
      <link>/2018/04/ruhrpy_meetup_2018_slides/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/ruhrpy_meetup_2018_slides/</guid>
      <description>On April 4th, 2018 I gave a talk about Deep Learning with Keras at the Ruhr.Py Meetup in Essen, Germany. The talk was not specific to Python, though - so if you’re intersted: the slides can be found here: https://www.slideshare.net/ShirinGlander/ruhrpy-introducing-deep-learning-with-keras-and-python
  Ruhr.PY - Introducing Deep Learning with Keras and Python  von Shirin Glander  There is also a video recording of my talk, which you can see here: https://youtu.</description>
    </item>
    
    <item>
      <title>My upcoming meetup talks about Deep Learning with Keras and explaining complex Machine Learning Models with LIME</title>
      <link>/2018/03/meetup_talk_ruhrpy_april_18/</link>
      <pubDate>Wed, 28 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/meetup_talk_ruhrpy_april_18/</guid>
      <description>I’ll be talking about Deep Learning with Keras in R and Python at the following upcoming meetup:
 Ruhr.Py 2018 on Wednesday, April 4th   Introducing Deep Learning with Keras and Python Keras is a high-level API written in Python for building and prototyping neural networks. It can be used on top of TensorFlow, Theano or CNTK. In this talk we build, train and visualize a Model using Python and Keras - all interactive with Jupyter Notebooks!</description>
    </item>
    
    <item>
      <title>Sketchnotes from TWiML&amp;AI #115: Scaling Machine Learning at Uber with Mike Del Balso</title>
      <link>/2018/03/twimlai115/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/twimlai115/</guid>
      <description>These are my sketchnotes for Sam Charrington’s podcast This Week in Machine Learning and AI about Scaling Machine Learning at Uber with Mike Del Balso:
Sketchnotes from TWiMLAI talk #115: Scaling Machine Learning at Uber with Mike Del Balso
 You can listen to the podcast here.
 In this episode, I speak with Mike Del Balso, Product Manager for Machine Learning Platforms at Uber. Mike and I sat down last fall at the Georgian Partners Portfolio conference to discuss his presentation “Finding success with machine learning in your company.</description>
    </item>
    
    <item>
      <title>Sketchnotes from TWiML&amp;AI #111: Learning “Common Sense” and Physical Concepts with Roland Memisevic</title>
      <link>/2018/02/twimlai111/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/twimlai111/</guid>
      <description>These are my sketchnotes for Sam Charrington’s podcast This Week in Machine Learning and AI about Learning “Common Sense” and Physical Concepts with Roland Memisevic:
Sketchnotes from TWiMLAI talk #111: Learning “Common Sense” and Physical Concepts with Roland Memisevic
 You can listen to the podcast here.
 In today’s episode, I’m joined by Roland Memisevic, co-founder, CEO, and chief scientist at Twenty Billion Neurons. Roland joined me at the RE•WORK Deep Learning Summit in Montreal to discuss the work his company is doing to train deep neural networks to understand physical actions.</description>
    </item>
    
    <item>
      <title>Announcing my talk about explainability of machine learning models at Minds Mastering Machines conference</title>
      <link>/2018/02/m3_2018/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/m3_2018/</guid>
      <description>On Wednesday, April 25th 2018 I am going to talk about explainability of machine learning models at the Minds Mastering Machines conference in Cologne. The conference will be in German, though.
  ERKLÄRBARKEIT VON MACHINE LEARNING: WIE KÖNNEN WIR VERTRAUEN IN KOMPLEXE MODELLE SCHAFFEN?
  Mit Machine-Learning getroffene Entscheidungen sind inhärent schwierig – wenn nicht gar unmöglich – nachzuvollziehen. Die Komplexität einiger der besten Modelle, wie Neuronale Netzwerke, ist genau das, was sie so erfolgreich macht.</description>
    </item>
    
    <item>
      <title>I talk about machine learning with Daniel Mies (Podcast in German, though)</title>
      <link>/2018/02/herr_mies_wills_wissen/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/herr_mies_wills_wissen/</guid>
      <description>For those of you out there who speak German:
I was interviewed for a tech podcast where I talked about machine learning, neural nets, why I love R and Rstudio and how I became a Data Scientist.
You can download and listen to the podcast here: https://mies.me/2018/01/31/hmww17-machine-learning-mit-dr-shirin-glander/
  In der aktuellen Episode gibt Dr. Shirin Glander (Twitter, Homepage) uns ein paar Einblicke in das Thema Machine Learning. Wir klären zunächst, was Machine Learning ist und welche Möglichkeiten es bietet bevor wir etwas mehr in die Tiefe gehen.</description>
    </item>
    
    <item>
      <title>JAX 2018 talk announcement: Deep Learning - a Primer</title>
      <link>/2018/01/jax2018/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/jax2018/</guid>
      <description>I am happy to announce that on Tuesday, April 24th 2018 Uwe Friedrichsen and I will give a talk about Deep Learning - a Primer at the JAX conference in Mainz, Germany.
 Deep Learning is one of the “hot” topics in the AI area – a lot of hype, a lot of inflated expectation, but also quite some impressive success stories. As some AI experts already predict that Deep Learning will become “Software 2.</description>
    </item>
    
    <item>
      <title>Sketchnotes from TWiML&amp;AI #94: Neuroevolution: Evolving Novel Neural Network Architectures with Kenneth Stanley</title>
      <link>/2018/01/twimlai94/</link>
      <pubDate>Sun, 28 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/twimlai94/</guid>
      <description>These are my sketchnotes for Sam Charrington’s podcast This Week in Machine Learning and AI about Neuroevolution: Evolving Novel Neural Network Architectures with Kenneth Stanley:
Sketchnotes from TWiMLAI talk #94: Neuroevolution: Evolving Novel Neural Network Architectures with Kenneth Stanley
 You can listen to the podcast here.
 Kenneth studied under TWiML Talk #47 guest Risto Miikkulainen at UT Austin, and joined Uber AI Labs after Geometric Intelligence , the company he co-founded with Gary Marcus and others, was acquired in late 2016.</description>
    </item>
    
    <item>
      <title>Sketchnotes from TWiML&amp;AI #92: Learning State Representations with Yael Niv</title>
      <link>/2018/01/twimlai92/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/twimlai92/</guid>
      <description>These are my sketchnotes for Sam Charrington’s podcast This Week in Machine Learning and AI about Learning State Representations with Yael Niv: https://twimlai.com/twiml-talk-92-learning-state-representations-yael-niv/
Sketchnotes from TWiMLAI talk #92: Learning State Representations with Yael Niv
 You can listen to the podcast here.
 In this interview Yael and I explore the relationship between neuroscience and machine learning. In particular, we discusses the importance of state representations in human learning, some of her experimental results in this area, and how a better understanding of representation learning can lead to insights into machine learning problems such as reinforcement and transfer learning.</description>
    </item>
    
    <item>
      <title>How to make your machine learning model available as an API with the plumber package</title>
      <link>/2018/01/plumber/</link>
      <pubDate>Tue, 16 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/plumber/</guid>
      <description>The plumber package for R makes it easy to expose existing R code as a webservice via an API (https://www.rplumber.io/, Trestle Technology, LLC 2017).
You take an existing R script and make it accessible with plumber by simply adding a few lines of comments. If you have worked with Roxygen before, e.g. when building a package, you will already be familiar with the core concepts. If not, here are the most important things to know:</description>
    </item>
    
    <item>
      <title>Sketchnotes from TWiML&amp;AI #91: Philosophy of Intelligence with Matthew Crosby</title>
      <link>/2018/01/twimlai91/</link>
      <pubDate>Sun, 14 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/twimlai91/</guid>
      <description>These are my sketchnotes for Sam Charrington’s podcast This Week in Machine Learning and AI about Philosophy of Intelligence with Matthew Crosby:https://twimlai.com/twiml-talk-92-learning-state-representations-yael-niv/
Sketchnotes from TWiMLAI talk #92: Philosophy of Intelligence with Matthew Crosby
You can listen to the podcast here.
This week on the podcast we’re featuring a series of conversations from the NIPs conference in Long Beach, California. I attended a bunch of talks and learned a ton, organized an impromptu roundtable on Building AI Products, and met a bunch of great people, including some former TWiML Talk guests.</description>
    </item>
    
    <item>
      <title>Looking beyond accuracy to improve trust in machine learning</title>
      <link>/2018/01/looking_beyond_accuracy_to_improve_trust_in_ml/</link>
      <pubDate>Wed, 10 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/looking_beyond_accuracy_to_improve_trust_in_ml/</guid>
      <description>I have written another blogpost about Looking beyond accuracy to improve trust in machine learning at my company codecentric&amp;rsquo;s blog:
 Traditional machine learning workflows focus heavily on model training and optimization; the best model is usually chosen via performance measures like accuracy or error and we tend to assume that a model is good enough for deployment if it passes certain thresholds of these performance criteria. Why a model makes the predictions it makes, however, is generally neglected.</description>
    </item>
    
    <item>
      <title>TWiMLAI talk 88 sketchnotes: Using Deep Learning and Google Street View to Estimate Demographics with Timnit Gebru</title>
      <link>/2018/01/twimlai88_sketchnotes/</link>
      <pubDate>Wed, 10 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/twimlai88_sketchnotes/</guid>
      <description>These are my sketchnotes taken from the “This week in Machine Learning &amp;amp; AI” podcast number 88 about Using Deep Learning and Google Street View to Estimate Demographics with Timnit Gebru:
Sketchnotes from TWiMLAI talk #88: Using Deep Learning and Google Street View to Estimate Demographics with Timnit Gebru
</description>
    </item>
    
    <item>
      <title>Blockchain &amp; distributed ML - my report from the data2day conference</title>
      <link>/2017/09/data2day/</link>
      <pubDate>Thu, 28 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/data2day/</guid>
      <description>Yesterday and today I attended the data2day, a conference about Big Data, Machine Learning and Data Science in Heidelberg, Germany. Topics and workshops covered a range of topics surrounding (big) data analysis and Machine Learning, like Deep Learning, Reinforcement Learning, TensorFlow applications, etc. Distributed systems and scalability were a major part of a lot of the talks as well, reflecting the growing desire to build bigger and more complex models that can’t (or would take too long to) run on a single computer.</description>
    </item>
    
    <item>
      <title>Data Science for Fraud Detection</title>
      <link>/2017/09/data-science-fraud-detection/</link>
      <pubDate>Wed, 06 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/09/data-science-fraud-detection/</guid>
      <description>I have written the following post about Data Science for Fraud Detection at my company codecentric&amp;rsquo;s blog:
 Fraud can be defined as “the crime of getting money by deceiving people” (Cambridge Dictionary); it is as old as humanity: whenever two parties exchange goods or conduct business there is the potential for one party scamming the other. With an ever increasing use of the internet for shopping, banking, filing insurance claims, etc.</description>
    </item>
    
  </channel>
</rss>